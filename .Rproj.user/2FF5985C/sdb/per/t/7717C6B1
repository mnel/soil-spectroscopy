{
    "contents" : "## some functions required for the calibration report for the RaCA project.\n\n## load and rename\n\nloadRename <- function(.fname, .name,...){\n## a function that loads a saved R object from a file\n## and allows you to rename it \n## .fname = the file name\n## .name the name of the object saved within that file  \n  load(as.character(.fname))\n  .df <- get(as.character(.name))\n  return(.df)\n}\n\n\n\nsaveObjectAs <- function(object,.fname, .name){\n## a function that allows you to save an object to file, with a different name to \n## that within your workspace\n## object = an 'R' object\n## .fname = the file name you wish to save it as\n## .name = the name within that file\n  assign(.name,object)\n  save(list = .name, file =.fname)\n  }\n\nsave_as <- function(.object, .name, .file_path, .ext = '.RData'){\n ## a function that allows you to save an object to file, with a different name to \n## that within your workspace\n## object = an 'R' object\n## .fname = the file name you wish to save it as\n## .name = the name within that file\n  assign(.name, .object)\n  save(list = .name, file = file.path(as.character(.file_path), paste(as.character(.name), as.character(.ext), sep = ''))) \n  \n}\n\n\ntable_to_data.frame <- function(.x, .id = 'id'){\n  ## create table\n  table_x <- table(.x)\n  ## make data.frame\n  .df <- data.frame(.names = names(table_x), count = as.numeric(table_x))\n  names(.df)[1] <- .id\n  return(.df)\n}\n\n## table to data frame\ntabDF <- function(x, ind = 'ind'){\n    ret <- data.frame(nam = names(x), count = as.numeric(x))\n    names(ret)[1] <- ind\n    ret\n  }\n\n## A function that gives the length of a vector without the NAs\n lengthNA <- function(x){length(na.omit(x))}\n\n## \nlength_NA <- function(.vector){length(na.omit(.vector))}\n\n\n## a function to find the number of profiles with data\n nUniqueProfiles <-  Vectorize(function(.data,.var, .profile = 'userPedonId'){\n    length(unique(.data[!is.na(.data[,.var]),.profile]))\n  }, vectorize.args ='.var')\n\nn_unique_ids <- Vectorize(function(.data, .var, .id){\n  length(unique(.data[!is.na(.data[,.var]), .id]))\n}, vectorize.args = '.var')\n\n##function to read in spectra from a file\n\nreadSpectra <- function(vnirNames, filePath, extension = '.txt'){\n  ## a function to read in from a .csv file, the second column containing the values\n  readFun <- function(x){read.csv(file.path(filePath, paste(x, extension, sep = '')), header = T)[,2]}\n  ## apply to a list\n   sList <-llply(vnirNames,readFun)\n  spectra <- do.call('rbind',sList)\n}\n\n\n\n\naverage_in_interval <- function(.spectra, .all, .in_interval){\n  \n}\n\n## A function to convert spectra to rgb\nspectraToRGB <- function(spectra){\n\n  blue <- mean(spectra[350:2500%in%(450:520)])\n  red <- mean(spectra[350:2500%in%(600:690)])\n  green <- mean(spectra[350:2500%in%(520:600)])\n  colour <- rgb(red,green,blue)\n data.frame(red,green,blue,colour)\n}\n\n\npropertiesLatex <- Vectorize(function(.name){\nswitch(as.character(.name) ,\n  'clay' = 'Clay', 'sand' = 'Sand', 'totalC' = 'Total C', \n  'estOrgC' = 'Organic C', 'cecClayRatio' = 'CEC:Clay', \n  'pHWater' = 'pH (Water)', 'pHCaCl' = 'pH $ \\\\left( {\\\\rm CaCl_2 } \\\\right)$',\n   'cecNH4' = 'CEC', 'feCD' = 'Iron Oxide', 'CaCO3' = '${\\\\rm CaCO_3}$'      ) \n})\n\ngetDatasetPLS <- function(.name){\n  library(Hmisc)\n  load(file.path('savedData','models', paste(.name,'PLSTrainingInfo.RData',sep ='')))\n  trainingInfo <- get( paste(.name,'PLSTrainingInfo',sep=''))\n  if(class(trainingInfo) == 'try-error'){stop(paste('No training info found for ', .name, '\\n'))}\n  training <- trainingInfo$training\n  whichData <- trainingInfo$whichData\n  \n  \n  trainingReflect <- data.frame(.var = soilData[training,.name], reflectance = I(as.matrix(reflect10SGD1[training,keep10])))\n  names(trainingReflect)[1] <- .name\n  trainingAbs <- data.frame(.var = soilData[training,.name], abs = I(as.matrix(abs10SGD1[training,keep10])))\n  names(trainingAbs)[1] <- .name  \n  validReflect <- data.frame(.var = soilData[-training,.name], reflectance = I(as.matrix(reflect10SGD1[-training,keep10])))\n  names(validReflect)[1] <- .name\n  validAbs <- data.frame(.var = soilData[-training,.name], abs = I(as.matrix(abs10SGD1[-training,keep10])))\n  names(validAbs)[1] <- .name  \n                                                                           \n  llist(trainingReflect, trainingAbs, validReflect, validAbs)     \n                                                                           \n  \n}\n\n\nmakeTrainingInfo <- function(.name, .allData, .savePath,.rate,...){\n    ## organize training info \n    .data <- .allData[,.name]\n    ## find the NAs and deal appropriately (remove from sampling pool)\n      whichNa <- attr( na.omit(.data) , 'na.action' )\n      all <-  1:length(.data)\n      if(is.null(whichNa)) {\n              whichData <- all} else{ \n              whichData <-  all[ -whichNa]}\n     ## create the training and validation  datasets\n    training <- sample(whichData, floor(.rate *length (whichData)) )\n    validation <- whichData[-training]\n    .dataTrain <- .data[training]\n    .dataValidate <- .data[validation]\n    ## stor the issues\n    trainingInfo <- llist(training, validation, whichData, .data, .dataTrain, .dataValidate )\n    ## rename and save\n    trainingInfo.name <- paste(.name,'PLSTrainingInfo',sep ='')\n    trainingInfo.fname <- file.path(.savePath, paste(trainingInfo.name, '.RData',sep=''))\n    saveObjectAs(trainingInfo, .fname = trainingInfo.fname, .name = trainingInfo.name)\n    data.frame(property = .name,trainingInfo.fname,trainingInfo.name, sampling = paste('.rate',.rate,sep='') )\n    }\n\nplsFit <- function(property, spectra.fname, spectra.name, trainingInfo.fname, trainingInfo.name, filter, .keep, \n                   sampling, .savePath,...){\n   ## load training info  \n   trainingInfo <- loadRename(trainingInfo.fname, trainingInfo.name )\n    ## load reflectance data\n    spectra <- loadRename(spectra.fname,spectra.name )\n     ## organize data\n    plsData <- data.frame(trainingInfo$.dataTrain, spectra = I(as.matrix(spectra[trainingInfo$training,.keep])))\n    names(plsData)[1]  <- as.character(property)\n    ## fit model\n    plsModel <- plsr(as.formula(paste(as.character(property), '~', 'spectra', sep = ' ')), data = plsData)\n    ## rename and save\n    model.name <- paste(.name,'PLS',.type,sep ='')\n    model.fname <- file.path(.savePath, paste(model.name, '.RData', sep = '' ))\n  \n   saveObjectAs(plsModel, .fname = model.fname, model.name = model.name)\n   ## tidyup \n   rm(list = c('plsData','spectra','plsModel','trainingInfo'))\n    gc()\n      \n   data.frame(property, model.fname,model.name, spectra = .type, sampling)\n  }\n\n\n\n\nplsrSummary <- function(.name){\n  ## load model\n  modelReflect <- loadRename(file.path('savedData','models', paste(.name,'PLSReflect.RData',sep ='')), paste(.name,'PLSReflect',sep =''))\n  ## load training data\n  trainingInfo <- loadRename(file.path('savedData','models', paste(.name,'PLSTrainingInfo.RData',sep ='')),paste(.name,'PLSTrainingInfo',sep ='') )\n  ## load spectra\n  spectraReflect <- loadRename('savedData/reflect10SGD1.RData', 'reflect10SGD1')\n  validationReflect <- data.frame(trainingInfo$.dataValidate, spectra = I(as.matrix(spectraReflect[trainingInfo$validation,keep10])))\n  names(validationReflect)[1] <- .name\n  ## Calculate statistics for training data set\n  reflectResultsTrain <- data.frame(components = 0:206, \n        rmsep = RMSEP(modelReflect)$val[,,1:207],\n        r2 = pls::R2(modelReflect)$val[,,1:207],\n        type = 'training')\n  ## calculate validation statistics\n  reflectResultsValid <- data.frame(components = 0:206,\n        rmsep = RMSEP(modelReflect, newdata = validationReflect)$val[,,1:207], \n        r2 = pls::R2(modelReflect,newdata = validationReflect)$val[,,1:207],\n        type = 'validation')\n  ## load absorbance model  \n  modelAbs <-loadRename(file.path('savedData','models', paste(.name,'PLSAbs.RData',sep ='')), paste(.name,'PLSAbs',sep ='') )\n  ## load absorbance data\n   spectraAbs <- loadRename('savedData/abs10SGD1.RData', 'abs10SGD1')\n  validationAbs <- data.frame(trainingInfo$.dataValidate, spectra = I(as.matrix(spectraAbs[trainingInfo$validation,keep10])))\n  names(validationAbs)[1] <- .name\n  \n  ## Calculate statistics for training data set\n  absResultsTrain <- data.frame(components = 0:206, \n        rmsep = RMSEP(modelAbs)$val[,,1:207],\n        r2 = pls::R2(modelAbs)$val[,,1:207],\n        type = 'training')\n  ## calculate validation statistics\n  absResultsValid <- data.frame(components = 0:206, \n        rmsep = RMSEP(modelAbs, newdata = validationAbs)$val[,,1:207],\n        r2 = pls::R2(modelAbs,newdata = validationAbs)$val[,,1:207],\n        type = 'validation')\n  ## organize results  \n  returning <- data.frame(rbind( reflectResultsTrain, reflectResultsValid,\n                                absResultsTrain, absResultsValid),\n                          using = as.factor(rep(c('reflectance', 'absorbance'), each= (207*2)\n                                                )\n                                            )\n                          )\n    \n  returning$id <- .name\n  returning$latexId <- propertiesLatex(.name)\n  returning\n}\n\n\ncubistFit <- function(.name, argList = list(x = 'reflect10SGD1', .fname = 'savedData/reflect10SGD1.RData', .type = 'Reflect')){\n  trainingInfo <- loadRename(file.path('savedData','models', paste(.name,'PLSTrainingInfo.RData',sep ='')),paste(.name,'PLSTrainingInfo',sep ='') )\n  .dataTrain <- trainingInfo$.dataTrain\n    ## load reflectance data\n    spectra <- loadRename(argList$.fname,argList$x )\n     ## organize data\n    cubistX <- data.frame(spectra[trainingInfo$training,keep10])\n    names(cubistX) <-      paste('w',seq(400,2450,by=10),sep='')\n    ## cubist model reflectance \n     cubistModel <- cubist(x = cubistX, y = .dataTrain)\n    ## fit model\n  ## rename and save\n    assign(paste(.name,'Cubist', argList$.type,sep =''), cubistModel)\n      ## save objects\n    save(list = paste(.name,'Cubist', argList$.type,sep =''),\n         file = file.path('savedData','models', paste(.name,'Cubist', argList$.type,'.RData',sep ='')))\n}\n\ncubistSummaryHelper <- function(.name,.type){\n  ## load model\n  cubistModel <- loadRename(file.path('savedData','models', paste(.name,'Cubist', .type,'.RData',sep ='')),paste(.name,'Cubist', .type,sep =''))\n  ## load training info\n  trainingInfo <- loadRename(file.path('savedData','models', paste(.name,'PLSTrainingInfo.RData',sep ='')),paste(.name,'PLSTrainingInfo',sep =''))\n  ## load spectra\n  if(.type == 'Reflect'){argList <- list( x = 'reflect10SGD1', .type ='Reflect', .fname = 'savedData/reflect10SGD1.RData')}\n  if(.type == 'Abs'){argList <- list( x = 'abs10SGD1', .type ='Abs', .fname = 'savedData/abs10SGD1.RData')}\n  spectra <- loadRename(argList$.fname,argList$x )\n   ## organize data\n   allData <- data.frame(spectra[,keep10])\n  names(allData) <-      paste('w',seq(400,2450,by=10),sep='')\n  ## make predictions\n  predCubist <- predict(cubistModel, newdata = allData)\n    ## create data frame with truth\n  resultsDF <- data.frame(truth = trainingInfo$.data, prediction = predCubist, using = .type)\n  ## get type\n   resultsDF$type <- 'xx'\n   resultsDF$type[is.na(trainingInfo$.data)] <- 'No Data'\n   resultsDF$type[trainingInfo$training] <- 'training'\n   resultsDF$type[trainingInfo$validation] <- 'validation'\n  \n  return(resultsDF)\n}\n  \n\ncubistSummary <- function(.name){\n  ## use the helper function\n   reflectDF <- cubistSummaryHelper(.name,.type='Reflect')\n   absDF <-  cubistSummaryHelper(.name,.type='Abs')\n  assessDF <- rbind(reflectDF, absDF)\n  ## calculate MSE\n  mseValues <- tapply(X=apply(assessDF[,1:2],1,function(x){diff(x)^2}),INDEX = with(assessDF, interaction(type,using)),FUN = mean)\n  data.frame(t(mseValues))\n   \n  }\n\n\nlibrary(KernSmooth)\ncHullDeviation <- function(.spectra, wavelengths = 350:2500, rangeB = 350:2500){\n  ## organize data\n  inData <- wavelengths %in% rangeB\n  .data <- sortedXyData(wavelengths[inData], .spectra[inData])\n  ## calculate convex rull\n  cHull <- chull(.spectra[inData])\n  cHull <- cHull[which(cHull==1):length(cHull)]\n  ## calculate linear approximation between hull points\n  linearApprox <- approx(.data[cHull,], xout = rangeB, method = 'linear', ties = 'mean')\n  \n  deviation <-  ( linearApprox[[2]] -.spectra[inData] )/linearApprox[[2]]\n  attr(deviation, 'hull') <-linearApprox[[2]]\n  return(deviation)\n}\n\ncHullDeviationAbs <- function(.abs, wavelengths = 350:2500, rangeB = 350:2500){\n  ## organize data\n  inData <- wavelengths %in% rangeB\n  .data <- sortedXyData(wavelengths[inData], .abs[inData])\n  ## calculate convex rull\n  cHull <- chull(.abs[inData])\n  cHull <- cHull[1:(which(cHull==1)-1)]\n  ## calculate linear approximation between hull points\n  linearApprox <- approx(.data[cHull,], xout = rangeB, method = 'linear', ties = 'mean')\n  \n  deviation <-  (  .abs[inData]-linearApprox[[2]] )\n  attr(deviation, 'hull') <-linearApprox[[2]]\n  return(deviation)\n}\n\n \ndrop0trailing.format <- function(x, ...) {\nformat(x,drop0trailing=T)\n }\n\n\nreadUSGS <- function(fName){\n  .data <- read.table(file = fName, skip=17, na.strings = '-1.23e34', \n                      col.names = c('wavelength', 'reflectance','sd'))\n  .data[,1] <- .data[,1] * 1000\n  .data\n}\n\n\nreadReference <- function(.fname, .detail){\n  ## read in spectra\n usgsSpectra <- readUSGS(as.character(.fname))\n .mineral = names(.fname)\n ## smooth to 1-nm data\n splineSmooth <- spline(usgsSpectra[,1:2], xout = 350:2500)\n ## get the mineral band range\n rangeMineral <- .detail[[.mineral]]$wvRange\n ## calculate the convex hull deviations\n crSpectra <- cHullDeviation(splineSmooth$y, rangeB = rangeMineral)\n ## organize into a data frame\n crSpectraReference <- data.frame(wavelength = rangeMineral, value = crSpectra )\n ## rename \n assign(paste('cr',.mineral,'Reference',sep=''),crSpectraReference)\n ## save\n save(list = c(paste('cr',.mineral,'Reference',sep='') ), file = paste('savedData/cr',.mineral,'Reference.RData',sep=''))\n}\n\n\n\nwideBandMin <-  function(.data, wideBand){which.min( 1 - .data[wideBand])}\n\nmaxID <- function(.spectra,.bandRange){data.frame(max = max(.spectra), which.max = .bandRange[which.max(.spectra)])}\n\nrelativeAbundance <- function(.spectra, .reference, .diagSpectra, .diagReference, bandWidth){\n  referenceValue <- .reference[bandWidth == .diagReference]\n  sampleValue <- .spectra[bandWidth == .diagSpectra]\n  sampleValue / referenceValue\n}\n\n\ncrMinerals <- function(.list, .spectraDetail= list(.fname = 'savedData/reflectAll.RData', .name ='reflectAll')){\n      ## load reflectance\n    spectra <- loadRename(.fname = .spectraDetail$.fname, .name = .spectraDetail$.name)\n    ## calculate chull deviations\n    .mineral = .list$.mineral\n    crRange <- apply(spectra, 1, cHullDeviation, rangeB = .list$wvRange)\n   \n    ## calculate some quantiles\n    crQ <-melt(data.frame( t( apply( crRange, 1, quantile,\n                          prob = c(0.05,0.06, 0.5,0.84, 0.95))), \n                       wavelength = .list$wvRange), id = 'wavelength')\n    ## rename the variable \n    levels(crQ$variable) <- c(0.05,0.06, 0.5,0.84, 0.95)\n     ## rename\n    assign(paste('crRange', .mineral, sep=''), crRange)\n    assign(paste('cr', .mineral,'Q', sep=''), crQ)\n      ## save data\n      save(list = c(paste('crRange', .mineral, sep='')), file = paste('savedData/crRange', .list$.mineral,'.RData', sep=''))\n      save(list = c(paste('cr', .mineral,'Q', sep='')), file = paste('savedData/cr', .list$.mineral,'Q.RData', sep=''))      \n}\n\n\nabundanceFunction <- function(.mineral){\n ## get reference spectra\n \n  referenceCR <- loadRename(.fname = paste('savedData/cr',.mineral,'Reference.RData',sep=''),.name = paste('cr',.mineral,'Reference',sep=''))\n## which are the wide band\n  whichWide <- referenceCR$wavelength %in% wideBandList[[.mineral]]\n  ## for reference spectra\n referenceID  <- which.min(1-referenceCR[whichWide,2])\n  ## what band is that\n diagnosticBand  <- referenceCR$wavelength[whichWide][referenceID]\n ## return\n return(llist(whichWide, referenceID, diagnosticBand))\n}\n  \nidMinima <- function(.List){\n  \n ## load data  \n .mineral <- .list$.mineral\n  crRange <- loadRename(.fname = paste('savedData/crRange',.mineral,'.RData',sep=''), .name = paste('crRange', .mineral, sep=''))\n ## and band range\n wideBand <- abundanceDiagnostics[[.mineral]]$whichWide\n mineralBands  <- apply( crRange, 2, wideBandMin, wideBand = wideBand)\n idBandMinima  <-  wideBandList[[.mineral]][mineralBands]\n ## cacluate derivative  \n idDeriv <- apply(apply(crRange,2,sgolayfilt,p=2,n=11,m=1)[wideBand,],2, function(x){ which.max(cumsum(x >0))})\n idBandDeriv <- wideBandList[[.mineral]][idDeriv]\n ## organize\n bandID <- data.frame(minima = idBandMinima,derivative = idBandDeriv)\n ## rename\n assign(paste('bandID',.mineral,sep =''), bandID)\n ## save\n save(list=c(paste('bandID',.mineral,sep ='')), file = file.path('savedData',paste('bandID',.mineral,'.RData',sep ='')))\n}\n\nfeAbundance <- function(.list){\n  .mineral <- .list$.mineral  \n  crRange <- loadRename(paste('savedData/crRange',.mineral,'.RData',sep=''),paste('crRange',.mineral,sep=''))\n  refVal <- max(get(paste('cr',.mineral,'Reference',sep=''))[,2])\n  abundance <- apply(crRange,2,max) / refVal\n  assign(paste('abundance',.mineral,sep=''), abundance)\n  save(list = c(paste('abundance',.mineral,sep='')), file = paste('savedData/abundance',.mineral,'.RData',sep=''))\n}\n\nmineralAbundance <- function(.list){\n ## load data\n  .mineral <- .list$.mineral\n  crRange <- loadRename( paste('savedData/crRange',.mineral,'.RData',sep=''),paste('crRange',.mineral,sep=''))\n  crRef <- loadRename( paste('savedData/cr',.mineral,'Reference.RData',sep=''),paste('cr',.mineral,'Reference',sep=''))\n  diagRef <- abundanceDiagnostics[[.mineral]]$diagnosticBand\n  diagSpec <-usedBands[.mineral]\n  bandRange <- .list$wvRange\n  ## calculate the relative Abundance\n  relAbundance  <- apply(crRange, 2, relativeAbundance,\n    .reference = crRef[,2], .diagSpectra = diagSpec, .diagReference= diagRef, bandWidth = bandRange)\n  ## rename\n  assign(paste('abundanceRelative',.mineral,sep =''), relAbundance)\n  ## save\n  save(list = c(paste('abundanceRelative',.mineral,sep ='')), file = paste('savedData/abundanceRelative',.mineral,'.RData',sep =''))\n  }\n\ncalcNIODI <- function(minerals = c('Goethite','Hematite')){\n  load(paste('savedData/crRange', minerals[1],'.RData', sep=''))\n  load(paste('savedData/crRange', minerals[2],'.RData', sep=''))\n  dHematite <- adply( crRangeHematite, 2,maxID, .bandRange = rangeHematite)\n  dGoethite <- adply( crRangeGoethite, 2,maxID, .bandRange = rangeGoethite)\n ## calculate \n NIODI <- n_I(dGoethite$max, dHematite$max)\n ## save\n  save(NIODI, file = 'savedData/NIODI.RData')\nreturn(NIODI)\n  }\n\nn_I <- function(A,B){\n  ab <- cbind(A,B)\n  ret <- (A-B)/ (A+B)\n  ##look for NA\n  both0 <- apply(ab,1, function(x){(x[1] == 0)&(x[2]==0)})\n  ret[both0] <- rep(0, table(both0)[2])\n  ret}\n\nsampleBy <- function(.id, .var, .inData,.rate,id.name){\n  ## where are the NAs?\n  .naVar <- is.na(.inData[[.var]])\n  ## unique ids (nas removed)\n  uniqueID <- as.character( unique ((.inData[!.naVar,])[,.id]))\n  allID <- as.character(unique(.inData[[.id]]))\n  ## sampled IDs\n  sampledIDs <- sample(uniqueID, size = floor(.rate * length(uniqueID)))\n  ## return list with sampled IDs, validation IDs and no data IDs\n  validationIDs <- uniqueID[!(uniqueID %in% sampledIDs )]                      \n  noDataIDs <- allID[!(allID %in% uniqueID)]\n  trainingRows <-  whichDataOut[.inData[,.id] %in% sampledIDs]\n  validationRows <- whichDataOut[.inData[,.id] %in% validationIDs]\n  ## remove NAs\n  trainingRows <- trainingRows[!is.na(.inData[trainingRows,.var])]\n  validationRows <- validationRows[!is.na(.inData[validationRows,.var])]\n  noDataRows <- whichDataOut[-c(trainingRows,validationRows)]\n  outPut <- llist(sampledIDs,validationIDs, noDataIDs,trainingRows,validationRows,noDataRows)                     \n  saveObjectAs(object = outPut, .name = paste(.var,id.name,'TrainingInfo',sep=''),.fname = paste('savedData/',.var,id.name,'TrainingInfo.RData',sep='') )\n  return(outPut)\n  }\n\ntileFunction <- function(.lev,max  = 2048 ,offset = 404){\n  wb <- offset + seq(max / 2^(.lev+1),max,by = max/2^(.lev))\n  geom_tile(data = data.frame(wb,scale=.lev), colour='black',fill=NA)\n}\n\nbandCentre <- function(.lev,max  = 2048 ,offset = 404){\n  offset + seq(max / 2^(.lev+1),max,by = max/2^(.lev))\n}\n\n\nbandCentreID <-  function(.lev,max  = 2048 ,offset = 404){\n  .level <- bandCentre(.lev,max=max,offset=offset)\n  paste('w',.level,.lev,sep='.')\n  \n}\n\nwaveCoefs <- function(wdObject,.lev,max  = 2048 ,offset = 404){\n  coefs <- accessD(wdObject,.lev)\n  names(coefs) <- bandCentreID(.lev, max = max, offset = offset)\n  coefs\n}\n\nmvOutlierRef <- function(.var,.sc = 5, .spectra, .subset = whichDataOut, .inData, .whichBands = keep10, .qcrit = 0.975){\n  ## load spectra\n  spectra <- loadRename(.fname = paste('savedData/',.spectra,'AllSGD1.RData',sep = ''), .name = paste(.spectra,'AllSGD1',sep = ''))\n  ## organize data\n  ## remove nas\n  whichUse <- .subset[!is.na(.inData[.subset,.var])]\n  plsData <- data.frame(.var = .inData[whichUse,.var], spectra = I(as.matrix(spectra[whichUse,.whichBands])))\n  ## run model\n  plsModel <- plsr(.var~spectra, data = plsData, ncomp = .sc)\n  ## get scores\n  plsScores <- scores(plsModel)\n  ## use Mahalanobis distance on scores\n  outlierTest <- sign1(plsScores, qcrit = .qcrit)\n  ## which samples are outliers\n  ## identify non-na \n  toUse <- whichUse[as.logical(outlierTest$wfinal01)]\n  potentialOutlier <- whichUse[!as.logical(outlierTest$wfinal01)] \n  \n  mvOut <- llist(toUse,potentialOutlier)\n  ## save\n  varname <- paste(.var,.spectra,'MVOutliers',sep='')\n  saveObjectAs(mvOut, .fname = file.path('savedData',paste(varname,'.RData',sep='')), .name = varname)\n  return(data.frame(nout = length(potentialOutlier), total = length(whichUse)))\n  }\n\n\noutlierMV <- function( .Data,.sc = 5, .subRows,.formula, .qcrit = 0.975, .dataCol){\n  ## load spectra\n  whichUse <- .subRows[!is.na(.Data[.subRows,.dataCol])]\n  plsData <- .Data[whichUse,]\n  ## run model\n  plsModel <- plsr(.formula, data = plsData, ncomp = .sc)\n  ## get scores\n  plsScores <- scores(plsModel)\n  ## use Mahalanobis distance on scores\n  outlierTest <- sign1(plsScores, qcrit = .qcrit)\n  ## which samples are outliers\n  ## identify non-na \n  toUse <- whichUse[as.logical(outlierTest$wfinal01)]\n  potentialOutlier <- whichUse[!as.logical(outlierTest$wfinal01)] \n  \n  mvOut <- llist(toUse,potentialOutlier)\n  mvOut\n  }\n\n\norderedSample <- function(.y,.mvOut){\n   \n   sorted <- .mvOut$toUse[order(.y[.mvOut$toUse])]\n   allRows <- seq(along=sorted)\n   vRows <- seq(3,length(allRows),by=3)\n   trainingRows <- sorted[allRows[-vRows]]\n   validationRows <- sorted[vRows]\n   outPut <- llist(trainingRows,validationRows)\n   outPut\n   }\n\nmakeTableDF <- function(.sampling){\n  .data <- melt(subset(samplingResults, sampling ==.sampling), measure.var = 'MSE', id.var = c('variable','using','dataset'))\n  rmse <- ddply(.data, ~dataset:using,function(x){sqrt(x$value)})\n  .df <- data.frame(t(rmse[,2:ncol(rmse)]))\n  names(.df) <- rmse[,'dataset:using']\n  .df <- .df[,paste( c('training','validation'),rep(c('reflect','abs'),each = 2),sep=':')]\n  row.names(.df) <-  as.character(sapply(whichProperties,propertiesLatex))\n  names(.df) <- paste(rep(c('Refl','Abs'),each = 2), c('(training)','(validation)'))\n## latexify\nxTabRMSE <- xtable(.df, digits=3)\n## and print using booktabs  \nprint(xTabRMSE,sanitize.text.function = function(x){x},floating=FALSE,hline.after=NULL,\n        add.to.row=list(pos=list(-1,0, nrow(xTabRMSE)),command=c('\\\\toprule ','\\\\midrule ','\\\\bottomrule ')))\n  }\n\n\norderedSampling <- function(.var,.spectra,.inData){\n   varname <- paste(.var,.spectra,'MVOutliers',sep='')\n   info <- loadRename(.fname = file.path('savedData',paste(varname,'.RData',sep='')), .name = varname)\n   sorted <- info$toUse[order(.inData[info$toUse,.var])]\n   allRows <- seq(along=sorted)\n   vRows <- seq(3,length(allRows),by=3)\n   trainingRows <- sorted[allRows[-vRows]]\n   validationRows <- sorted[vRows]\n    outPut <- llist(trainingRows,validationRows)\n  saveObjectAs(object = outPut, .name = paste(.var,'MVOTrainingInfo',sep=''),.fname = paste('savedData/',.var,'MVOTrainingInfo.RData',sep='') )\n}\n\noutlierSample <- function(.var){\n  load('savedData/mvOutliers.RData')\n  inSamples <- whichDataOut[!is.na(soilDataOut[,.var])]\n  outlier <- mvOutliers[[.var]]$outlier\n  inSamples2 <- inSamples[!outlier]\n  orderVar <- order(soilDataOut[inSamples2,.var])\n  sortVar <-  sort(soilDataOut[inSamples2,.var])\n  trainingRows <- inSamples2[orderVar][c(seq(1,length(orderVar),by=3), seq(2, length(orderVar),by=3))]\n  validationRows <- inSamples2[orderVar][seq(3,length(orderVar),by=3)]\n  outPut <- llist(trainingRows,validationRows)\n  saveObjectAs(object = outPut, .name = paste(.var,'MVOTrainingInfo',sep=''),.fname = paste('savedData/',.var,'MVOTrainingInfo.RData',sep='') )\n}\n\ncubistSamplingFit <- function(.name,.type,.spectra){\n  ## load sampling info\n  trainingInfo <- loadRename(.fname = paste('savedData/',.name,.type,'TrainingInfo.RData',sep=''), .name = paste(.name,.type,'TrainingInfo',sep=''))\n  trainingData <- soilData[trainingInfo$trainingRows,.name]\n  spectra <- loadRename(paste('savedData/',.spectra,'10SGD1.RData',sep=''),paste(.spectra,'10SGD1',sep=''))\n  cubistX <- as.data.frame(spectra[trainingInfo$trainingRows,keep10])\n  names(cubistX) <- paste('w',seq(400,2450,by=10),sep='')\n  cubistModel <- cubist(x = cubistX, y = trainingData)\n  ## save the results\n  .name <-  paste(.name,.spectra,.type,'Cubist',sep ='')\n  saveObjectAs(cubistModel,.fname = file.path('savedData','models',.name), .name=.name)\n}\n\n\n## and summarize\ncubistSummaryHelperSampling <- function(.name,.type, .spectra){\n  mname <- paste(.name,.spectra,.type,'Cubist',sep ='')\n  tname <- paste(.name,.type,'TrainingInfo',sep='')\n  ## load model\n  cubistModel <- loadRename(file.path('savedData','models', paste(mname,sep ='')), mname)\n  ## load training info\n  trainingInfo <-  loadRename(.fname = paste('savedData/',.name,.type,'TrainingInfo.RData',sep=''), .name = tname)\n  ## load spectra\n  argList <- list( x = paste(tolower(.spectra),'10SGD1',sep=''), .type = .spectra, .fname =paste('savedData/', tolower(.spectra),'10SGD1.RData',sep='') )\n  spectra <- loadRename(argList$.fname,argList$x )\n   ## organize data\n   allData <- data.frame(spectra[,keep10])\n  names(allData) <-      paste('w',seq(400,2450,by=10),sep='')\n  ## make predictions -- training\n  fittedCubist <- predict(cubistModel, newdata = allData[trainingInfo$trainingRows,])\n  predictedCubist <- predict(cubistModel, newdata = allData[trainingInfo$validationRows,]) \n  fittedMAE <- mean(abs(soilData[trainingInfo$trainingRows,.name] - fittedCubist),na.rm = T)\n  validMAE <- mean(abs(soilData[trainingInfo$validationRows,.name] - predictedCubist),na.rm = T)\n  fittedMSE <- mean((soilData[trainingInfo$trainingRows,.name] - fittedCubist)^2,na.rm=T)\n  validMSE <- mean((soilData[trainingInfo$validationRows,.name] - predictedCubist)^2, na.rm =T)\n  \n  data.frame(MAE = c(fittedMAE,validMAE), \n             MSE  = c(fittedMSE,validMSE),\n             dataset = as.factor(c('training','validation')),\n             sampling = .type, using = .spectra,variable = .name)\n}\n\n\ncubistSamplingSummary <- function(termList){\n  .name <- termList$.name\n  .type <- termList$.type\n  .spectra <- termList$.spectra\n  df <- cubistSummaryHelperSampling(.name,.type,.spectra)\n\n}\n\n\n\npower2 <- function(.char){paste(.char,'+I(',.char,'^2)')}\nmakeFormula <- function(.names,.y){\n  as.formula(paste(.y, '~',paste(sapply(.names,power2),collapse='+')))\n}\n\nwaveletModel <- function(.var,.coefs,.which,.number, .inData){\n  ## load training Info\n  info <- loadRename(.name = paste( .var, 'MVOTrainingInfo', sep = ''), .fname = paste('savedData/', .var, 'MVOTrainingInfo.RData', sep = ''))\n  ## create data frames\n  trainingData <- data.frame(.var = .inData[info$trainingRows,.var],.coefs[info$trainingRows,])\n  validationData <- data.frame(.var = .inData[info$validationRows,.var],.coefs[info$validationRows,])\n  ## make formula\n  waveFormula <- makeFormula(.names = names(.coefs)[varOrder[1:.number]], .y = '.var')\n  ## fit model\n  waveModel <- lm(waveFormula,trainingData )\n  ## calculate adjusted R squared\n  adjR2 <- summary(waveModel)$adj.r.squared\n  \n  ## predict\n  validationPredict <- predict(waveModel, newdata = validationData)\n  ## and calculate RMSE\n  rmse <- sqrt( mean( (validationData$.var - validationPredict )^2,na.rm=T) )\n  \n  data.frame(adjR2, rmse)\n  \n}\n\n\n",
    "created" : 1327544978557.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "hash" : "3715708655",
    "id" : "7717C6B1",
    "lastKnownWriteTime" : 1327432148,
    "path" : "~/Documents/soil-spectroscopy/racaFunctions.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}